---
title: "Machine Learning Course Project"
author: "Erik Johnson"
date: "November 21, 2017"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Synopsis
In this project, we aim to create a model that predicts how well people perform various barbell lifts, given data from accelerometers on the belt, forearm, arm, and dumbell. Specifically, we aim to classify whether they perform the lifts correctly, or incorrectly in one of 5 different ways. Using the dataset provided for the project, we built a random forest model that achieves an estimated out-of-sample error rate of 0.27%.

## Data Preparation
We start by loading the data from the file.
```{r libraries,message=FALSE}
library(caret)
```
```{r readdata}
rawData <- read.csv("pml-training.csv")
```

Next, we remove near-zero valued columns, descriptive columns that don't contribute to the prediction (e.g., timestamp), and columns with almost all NA values.
```{r removeNearZero}
# Look for near-zero variables
nzv <- nearZeroVar(rawData,saveMetrics=TRUE)
# Remove near-zero variables
dat <- rawData[,nzv$nzv == FALSE]
```
```{r removeNameColumns}
# Remove descriptive variables
descriptiveColumns <- grepl("X|user_name|raw_timestamp_part_1|raw_timestamp_part_2|cvtd_timestamp", names(dat))
dat <- dat[,!descriptiveColumns]
```
```{r removeNAColumns}
# Get the percent of NA values for each column
colNAPercentages <- sapply(names(dat), function(colName){sum(is.na(dat[[colName]]))/nrow(dat)})
# Keep columns with less than 97% NA values
dat <- dat[,names(colNAPercentages[colNAPercentages < 0.97])]
```

We finish our data preparation by partitioning the data into training and test sets.
```{r partitionData}
# Create training and testing partitions
set.seed(32465)
inTrain <- createDataPartition(y=dat$classe, p=0.7, list=FALSE)
training <- dat[inTrain,]
testing <- dat[-inTrain,]
```

## Model Building
Our strategy of model creation is to try several models and pick the one with the best accuracy. Since this is a non-linear problem, we only try models that perform best in non-linear scenarios: random forests, decision trees, boosting with trees, naive bayes, and linear discriminant analysis.

For each model, we estimate its out-of-sample accuracy and error by predicting on the testing data partition. We use 10-fold cross-validation to reduce bias.

```{r trainControl}
trControl <- trainControl(method="cv", 10)
```

### Random Forest
```{r fitRF,cache=TRUE}
# Train a random forest model
fitRF <- train(classe ~ ., data=training, method="rf", trControl=trControl)
```
```{r fitRFCheck}
# Check the accuracy on the testing partition
predFitRF <- predict(fitRF, testing)
confFitRF <- confusionMatrix(testing$classe, predFitRF); confFitRF;
```
```{r plotFitRF}
plot(fitRF)
```

### Decision Trees
```{r fitRPart,cache=TRUE}
# Train a decision tree model
fitRPart <- train(classe ~ ., data=training, method="rpart", trControl=trControl)
```
```{r fitRPartCheck}
# Check the accuracy on the testing partition
predFitRPart <- predict(fitRPart, testing)
confFitRPart <- confusionMatrix(testing$classe, predFitRPart); confFitRPart;
```
```{r plotFitRPart}
plot(fitRPart)
```

### Boosting With Trees
```{r fitGBM,cache=TRUE}
# Train a boosting with trees model
fitGBM <- train(classe ~ ., data=training, method="gbm", trControl=trControl, verbose=FALSE)
```
```{r fitGBMCheck}
# Check the accuracy on the testing partition
predFitGBM <- predict(fitGBM, testing)
confFitGBM <- confusionMatrix(testing$classe, predFitGBM); confFitGBM;
```
```{r plotFitGBM}
plot(fitGBM)
```

### Naive Bayes
```{r fitNB,cache=TRUE,message=FALSE,warning=FALSE}
# Train a naive bayes model
fitNB <- train(classe ~ ., data=training, method="nb", trControl=trControl)
```
```{r fitNBCheck,message=FALSE,warning=FALSE}
# Check the accuracy on the testing partition
predFitNB <- predict(fitNB, testing)
```
```{r confusionMatrixNB}
confFitNB <- confusionMatrix(testing$classe, predFitNB); confFitNB;
```
```{r plotFitNB}
plot(fitNB)
```

### Linear Discriminant Analysis
```{r fitLDA,cache=TRUE}
# Train a linear discriminant analysis model
fitLDA <- train(classe ~ ., data=training, method="lda", trControl=trControl)
```
```{r fitLDACheck}
# Check the accuracy on the testing partition
predFitLDA <- predict(fitLDA, testing)
confFitLDA <- confusionMatrix(testing$classe, predFitLDA); confFitLDA;
```

## Model Selection
We see that the random forest model performs best, with an estimated out-of-sample accuracy of `r round(100*confFitRF$overall["Accuracy"],digits=2)`% and out-of-sample error of `r round(100*(1 - confFitRF$overall["Accuracy"]),digits=2)`% (as estimated via predicting on the testing data partition). Therefore, we select this model to use on the test dataset.

## Test Class Prediction
We use the random forest model we created previously to predict the weight training class in the test dataset.

We start by loading the test data.
```{r loadTestData}
testData <- read.csv("pml-testing.csv")
```

Finally, we predict the classe of the test data.
```{r testPrediction}
testPrediction <- predict(fitRF, testData)
testPrediction
```




